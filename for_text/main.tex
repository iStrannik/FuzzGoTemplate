\documentclass[a4paper]{article}
\usepackage[14pt]{extsizes}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{setspace,amsmath}
\usepackage[left=20mm, top=15mm, right=15mm, bottom=15mm, nohead, footskip=10mm]{geometry}
\usepackage[pdftex]{lscape}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
\usepackage{graphicx}
\graphicspath{{./}}
\graphicspath{{./pictures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage[tableposition=top,singlelinecheck=false]{caption}
\usepackage{subcaption}
\DeclareCaptionLabelFormat{gostfigure}{Рисунок #2}
\captionsetup*[figure]{labelformat=gostfigure, justification=centering}
\usepackage{amsfonts}
\setcounter{tocdepth}{2}

\begin{document}
 
\begin{center}
\includegraphics{MSU}

\hfill \break
\normalsize{Московский государственный университет имени М.В. Ломоносова}\\
\normalsize{Факультет вычислительной математики и кибернетики}\\
\normalsize{Кафедра информационной безопаснсти}\\
\normalsize{Лаборатория безопасности информационных систем}\\
 \hfill \break
\normalsize{Николайчук Артём Константинович}\\
\hfill\break
\hfill \break
\hfill \break
\hfill \break
\large{Исследование методов автоматической генерации входных данных для тестирования модулей обработки шаблонов веб-страниц}\\
\hfill \break
\hfill \break
\hfill \break
\normalsize{ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА}\\
\hfill \break
\hfill \break
\hfill \break
\hfill \break
\hfill \break
\hfill \break
\hfill \break
\hfill \break
\begin{flushright}
    \normalsize{Научный руководитель:}\\
    \normalsize{м.н.с}\\
    \normalsize{А.А.Петухов}\\
\end{flushright}
\end{center}
\vspace*{\fill}
\begin{center} Москва, 2023 \end{center}
\thispagestyle{empty}
 
\newpage
\section*{Аннотация}
\indent

В настоящее время разработчики всё больше беспокоятся о безопасности создаваемых приложений. Цена ошибки или бага может быть очень высокой. Тестирование стало неотъемлемой частью жизненного цикла разработки программного обеспечения. Некоторые программы, такие как шаблонизаторы, парсеры, интерпретаторы, компиляторы, обрабатывают данные, которые имеют сложную структуру. Вручную написать тесты с приемлемым покрытием для этих программ не представляется возможным. Для них разумно применять методы генерации тестов, а также fuzz-тестирования поверх этих методов для поиска ошибок. Эти методы подлежат обзору для того, чтобы оценить их
применимость для поиска недостатков безопасности шаблонизаторов. Для исследования их применимости разработан фаззер для стандартного шаблонизатора языка Golang.
\newpage
    \tableofcontents
\newpage
 
\newpage
\section{Введение}

\subsection{Введение в предметную область}

\subsubsection{Шаблонизаторы}
\indent
Шаблонизаторы - это программные инструменты, которые используются для автоматического генерирования HTML-кода и других статических документов из динамических данных. Они позволяют разработчикам создавать и использовать шаблоны, которые определяют структуру и внешний вид веб-страниц, не привязываясь к конкретным данными. Шаблонизаторы обычно основаны на языках программирования, таких как Python, PHP, Golang, Java и JavaScript. Они широко используются в веб-разработке, чтобы создавать динамические веб-сайты и приложения.

Шаблон - текст, содержащий строковые константы и специальные конструкции шаблонизатора. Пример шаблона предоставлен на рисунке \ref{GolangExample}

\begin{figure}[ht!]
\includegraphics[width=140mm]{SimpleGoTemplate.png}
\caption{Пример шаблона на языке Golang}
\label{GolangExample}
\end{figure}

Движок шаблонизатора - программное обеспечение, разработанное для объединения шаблона и данных в финальный документ. При работе шаблонизатора сначала производится лексический и семантический анализ шаблона. Затем шаблонизатор обрабатывает все встреченные служебные блоки. В них могут быть заложены как простые конструкции - например, подставить значение переменной, так и более сложные выражения, такие как условные операторы, циклы, вызовы функций. Шаблонизатор подставляет значения из доступных ему данных в обозначенные места в шаблоне. Пример того, как должна быть сформирована структура этих данных в программе предоставлен на рисунке \ref{GolangWorkExample}. Шаблонизатору во время рендеринга шаблона доступна строковая переменная $PageTitle$, её значение он подставит в тег $h1$, и массив структур $Todos$. Конструкция $range$ в шаблоне означает перебор всех элементов массива. Для каждого элемента выведется его поле $Title$ в списке, при этом если значение поля $Done$ будет истинным, то в результат добавится дополнительно $class="done"$.

\begin{figure}[!tbp]
\centering
\subfloat[структура данны для подстановки в шаблон]{\includegraphics[width=0.4\textwidth]{DataForGoTemplate.png}\label{fig:1}}
\hfill
\subfloat[результат работы шаблонизатора]{\includegraphics[width=0.4\textwidth]{GolangResultHtml.png}\label{fig:2}}
\caption{Пример работы шаблонизатора}
\label{GolangWorkExample}
\end{figure}

\subsubsection{Уязвимости в шаблонизаторах}
\indent

В мире веб-приложений шаблонизаторы часто используются для работы с данными, полученными от пользователей. Рассмотрим типовые примеры атак и известных уязвимостей в шаблонизаторах.

\paragraph{Уязвимости типа XSS}
\indent

Атака xss возможна, если данные, полученные от пользователя, некорректно обрабатываются и попадают в html-разметку. В качестве примера рассмотрим шаблон из рисунка \ref{GolangExample} и предположем, что поле $PageTitle$ задаётся пользователем. Пусть переменная $PageTitle$ содержит строку $$<script>alert(documnet.cookie)</script>$$ Тогда если у шаблонизатора отсутствует механизм защиты от xss, то появляется возможность украсть пользовательские куки. Стандартный механизм защиты от атак этоги типа - экранирование символов. Экранирование - это процесс замены опасных для безопасности символов на безопасные, которые могут быть безопасно отображены в документе, и является важной составляющей безопасности веб-приложений. Этот механизм реализуют многие современные шаблонизаторы, в некоторых эта опиция включена по умолчанию, в некоторых требуется дополнительно указывать необходимость экранирования. В первом случае шаблонизатор может выполнять экранирование символов, опираясь на контекст, в который попадают данные. Например, стандартный шаболонизатор языка Golang(пакет html/template) может распознавать контексты HTML, CSS, JavaScript и URL, и в них по-разному экранировать одну и ту же строку \footnote{\href{https://pkg.go.dev/html/template\#hdr-Contexts}{https://pkg.go.dev/html/template\#hdr-Contexts}} (рисунок \ref{GoEscaping}).

\begin{figure}[ht!]
    \includegraphics[width=140mm]{GoEscaping.png}
    \caption{Пример экранирования строки O'Reilly: How are <i>you</i>? в разных контекстах}
    \label{GoEscaping}
    \end{figure}

Примеры известных уязвимостей:

\begin{itemize}
\item Ошибка в экранировании контекстных переменных в шаблонизаторе Django - CVE-2022-22818\footnote{\href{https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-22818}{https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-22818}}, при использовании специального тега \{\% debug \%\}.

\item Уязвимость в шаблонизаторе Mako - CVE-2010-2480\footnote{\href{https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2010-2480}{https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2010-2480}}. Ошибка в том, что в Mako для экранирования использовалась функция стандартной библиотеки языка программирования Python, которая некорректно обрабатывала символ кавычки '.  Атакующий мог проэксплуатировать этот недостаток, воспользовавшись функцией onload для любого html-тега. Пример эксплойта - ' onload=alert(1) a='
\item Уязвимость в шаблонизаторе Mustache - CVE-2022-40313\footnote{\href{https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-40313}{https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-40313}}. Рекурсивный рендеринг в шаблонах Mustache, содержащих пользовательский ввод, в некоторых случаях мог привести к XSS.
\end{itemize}

\paragraph{Уязвимости типа SSTI}
\indent

SSTI (Server-side template injection) - это уязвимость, которая возникает, когда злоумышленник может выполнить произвольный код на стороне сервера, используя уязвимости шаблонизатора.

Шаблонизатор Jinja подвержен такой уязвимости, если происходит вставка пользовательских данных в шаблон без предварительной проверки на потенциально опасные символы. Например, если в приложении есть возможность ввода данных пользователем, которые затем используются для формирования HTML-шаблона на сервере, то злоумышленник может вставить в поле ввода код, который будет выполнен на сервере. Рассмотрим пример такой уязвимости. В коде программы(рисунок \ref{SSTIJinja}) в формировании шаблона используются данные, полученные от пользователя. Если подставить в уязвимый параметр name строку \{\{ 1 + 1\}\} , то сложение выполнится. 

\begin{figure}[ht!]
    \includegraphics[width=140mm]{SSTIJinja.png}
    \caption{Пример шаблона, узявимого к SSTI}
    \label{SSTIJinja}
    \end{figure}

\subsubsection{Fuzz-тестирование}
\indent

Fuzz-тестирование - способ автоматического тестирования программного обеспечения. Фаззер генерирует случайные входные данные и улучшает, или изменяет их, затем анализирует работу программы на этих данных, и пытается обнаружить потенциальные дефекты или уязвимости программного обеспечения. Фаззеры принято классифицировать по принципу генерации данных\footnote{\href{https://habr.com/ru/company/dsec/blog/517596/\#chto-takoe-fazzing}{https://habr.com/ru/company/dsec/blog/517596/\#chto-takoe-fazzing}}:


\begin{itemize}
\item Мутационные фаззеры обрабатывают заранее подготовленное множество входных данных. Наиболее популярными изменениями являются заимствованные из биологии мутации и скрещивания. Мутации - это изменение какой-то части входных данных на случайную. При скрещивании выбираются два примера, которые обмениваются друг с другом частью данных.
\item Генерационные фаззеры создают новые примеры, основываясь на информации о требуемой структуре входных данных. 
\item Смешанные фаззеры объединяют в себе два предыдущих подхода. Например, при мутации данные могут меняться не на случайные, а на сгенерированные. Или фаззер может сначала создать пул тестовых данных и к нему применять мутационный метод. 
\end{itemize}

В рамках поиска ошибок в шаблонизаторах наибольший интерес представляет подход с генерацией входных данных, так как каждый шаблон должен удовлетворять правилам движка, чтобы проходить тривиальные проверки при запуске.

На практике оказалось очень удобно задавать структуру входных данных с помощью грамматик (Пример грамматики на рис. \ref{SimpleGrammar}). Если известна грамматика, то все возможные входные данные можно представить абстрактным синтаксическим деревом (далее АST - Abstract Syntax Tree). Пример AST представлен на рисунке \ref{SimpleAST}. Это позволяет избегать синтаксических ошибок на этапе запуска программы. В дальнейшем будет показано, что такое представление полезно при генерации и мутации данных.

\begin{figure}[ht!]
\includegraphics[width=180mm]{Expressions_Grammar.png}
\caption{Грамматика арифметических выражений}
\label{SimpleGrammar}
\end{figure}

\begin{figure}[ht!]
\includegraphics[width=100mm]{SimpleAST.png}
\caption{AST для выражения 1 + (2 * 3)}
\label{SimpleAST}
\end{figure}

\subsection{Цель работы}

Цель данной работы - исследовать применимость методов автоматической генерации входных данных для тестирования модулей обработки шаблонов веб-страниц. Для достижения этой цели необходимо рассмотреть существующие методы fuzz-тестирования, проанализировать их и выбрать наиболее подходящие для шаблонизаторов. Исследовать применимость этих методов экспериментальным способом.



\subsection{Постановка задачи}
\begin{enumerate}
    \item Исследовать предметную область fuzz-тестирования на основе грамматик.
        \begin{itemize}
        \item Сформировать критерии для сравнения методов.
        \item Проанализировать существующие решения по выделенным критериям.
        \item Дать оценку каждому критерию.
        \item Сделать вывод о том, какие методы будут использованы в фаззере.
        \end{itemize}
    \item Исследовать существующие инструменты fuzz-тестирования и генерации входных данных по грамматике, и определить, какие из них можно будет переиспользовать при разработке своего фаззера.
    \item Разработать прототип фаззера
        \begin{itemize}
        \item Разработать фаззер для стандартного шаблонизатора языка Golang, реализовав определённые на этапе анализа методы.
        \item Провести эксперименты, подобрать оптимальные параметры для фаззера, в том числе внести доработки в предложенную архитектуру фаззера. 
        \item Сделать вывод об эффективности каждого из методов.
        \end{itemize} 
    \item Сделать вывод о применимости методов fuzz-тестирования для тестирования шаблонизаторов.
\end{enumerate}

\newpage
\section{Анализ задачи}
\indent

\subsection{Выбор исследуемой функциональности}

Как было отмечено ранее, в шаблонизаторах существуют два основных типа уязвимостей: SSTI и XSS.
Уязвимость типа SSTI является следствием ошибки разработчика при использовании шаблонизатора. Такие ошибки не интересны с точки зрения безопасности самого шаблонизатора. 

Уязвимость типа XSS возможна в одном из двух случаев:

\begin{itemize}
    \item Экранирование не должно было быть выполнено - либо шаблонизатор не гарантирует экранирование, либо была использована специальная функция, отключающая этот механизм безопасности. Это неправильная конфигурация шаблонизатора, то есть с точки зрения программы ошибки тут нет.
    \item Шаблонизатор сконфигурирован правильно, но специальные символы не экранируются. Такие ошибки предлагается искать при помощи fuzz-тестирования.
\end{itemize}

\subsection{Особенности шаблонизатора Golang}
В официальной документации указано, что шаблонизатор является безопасным.\footnote{\href{https://pkg.go.dev/html/template\#hdr-Security\_Model}{https://pkg.go.dev/html/template\#hdr-Security\_Model}} Как было отмечено ранее, шаблонизатор умеет различать контексты HTML, JS, CSS и URL. Механизм экранирования символов включён по умолчанию. На данный момент в шаблонизаторе не было найдено ни одной уязвимости. Шаблонизатор реализует довольно обширный список синтаксических конструкций, основные из них: 
\begin{itemize}
    \item Условный оператор if/else
    \item Оператор цикла range
    \item Встроенные функции сравнения данных, вычисления логических выражений, получения элементов массива по индексу и получения подмассива. Помимо встроенных, шаблонизатор позволяет создавать свои функции и использовать их в шаблоне.
    \item Возможность создавать переменные внутри шаблона и использовать их значения.
\end{itemize}
Таким образом, шаблонизатор реализует нужный механизм безопасности(механизм экранирования символов), который включён по умолчанию, и не требует при использовании никаких дополнительных действий.

Основные особенности шаблонизатора, которые нужно будет учитывать при разработке фаззера:

\begin{itemize}
    \item Язык Golang является строго типзированным языком, и данные, которые обрабатывает шаблон также должны быть строго типзированы. Данные в шаблон передаются одной структурой, обращаться к ним нужно через название полей структуры. Наример, конструкция в шаблоне \{\{ .Student.Name \}\} обращается к полю Student входной структуры, а затем к полю Name структуры Student. Появляется проблема соответствия названий переменных в шаблоне и названий переменных в структуре, которая передаётся из кода программы. 
    \item Возможность создавать и запускать собственные функции. Задача сгенерировать всевозможные функции изначально не является выполнимой, так как их счётное число.
\end{itemize}

\subsection{Требования к фаззингу шаблонизатора}

Исследуемый функционал - корректное экранирование символов шаблонизатором. Чтобы протеститровать этот функционал, фаззер должен генерировать разнообразные синтаксически валидные тесты и иметь возможность проверки правильности экранирования. Для корректности создаваемых тестов должна быть решена проблема соответсвия названий и типов данных в шаблоне и в программе, обрабатывающей этот шаблон. Для полноты исследования функциональности экранирования требуется протестировать как можно больше вариантов различных контекстов и обрабатываемых в них данных.

\newpage
\section{Анализ предметной области fuzz-тестирования на основе грамматик}
\indent

В основе анализа лежат энциклопедия фаззинга - fuzzingbook\footnote{\href{https://www.fuzzingbook.org/}{https://www.fuzzingbook.org/}} и статьи c google scholar, в которых описываются современные подходы к fuzz-тестированию на основе грамматик. Fuzzingbook - сборник всех базовых идей и концепций, применяемых в fuzz-тестировании.

Согласно fuzzingbook, базовый алогоритм\footnote{\href{https://www.fuzzingbook.org/html/Fuzzer.html}{https://www.fuzzingbook.org/html/Fuzzer.html}} работы любого фаззера состоит из следующих шагов:

\begin{enumerate}
    \item Предобработка тестируемого программного обеспечения(далле SUT - Soft Under Test). Например, она может заключаться в компиляции со специальными флагами или подготовке окружения для тестирования. 
    \item Получить начальное множество входных данных и создать из него пул тестов.
    \item Выбрать из пула один или несколько примеров и получить результат их тестирования в SUT.
    \item Решить будет ли полезен этот тест в будущем.
    \item Мутировать тест и добавить его в пул.
    \item Перейти к шагу 3.
\end{enumerate}

Ниже подробно описаны идеи, которые можно применять в каждом из пунктов. Все они взяты из статей - \cite{litlink1}, \cite{litlink2}, \cite{litlink3}, \cite{litlink4}, \cite{litlink5}, \cite{litlink6}, \cite{litlink7}, \cite{litlink8}.

\subsection{Получение начального множества тестов}
\indent

Первый способ получения входных данных\cite{litlink3} - использовать тесты, которые написали разработчики для SUT. Этот способ позволяет сразу получить хорошее покрытие кода. При обнаружении бага разработчики исправляют его и часто добавляют тест, который проверяет работоспособность программы в этом месте. В этом смысле тесты, как начальное множество, позволяют сразу добираться до "слабых" мест в SUT. Минус этого способа - тесты разработчиков не всегда доступны.
\indent

Второй вариант\cite{litlink3} - собрать пул тестов из примеров в интернете. Например, в случае fuzz-тестировании интерпретатора javascript можно в начальное множество добавлять примеры javasrcipt кода с гитхаба. Таким способом можно получить широкий пул тестов.
\indent

Третий\cite{litlink2} - можно сгенерировать множество самостоятельно. В этом случае появляется возможность подтолкнуть фаззер в определённом направлении. Детали процесса генерации описаны ниже.

\subsection{Генерация тестов}
\indent

\subsubsection{Способы генерации}
\indent

Алгоритм создания тестовых данных опирается на знание их структуры. Как было отмечено ранее, эту структуру удобно задавать контекстно-свободной грамматикой. В этом случае процесс генерации нового теста заключается в построении его AST. Шаги алгоритма\footnote[1]{\href{https://www.fuzzingbook.org/html/Grammars.html\#A-Simple-Grammar-Fuzzer}{https://www.fuzzingbook.org/html/Grammars.html\#A-Simple-Grammar-Fuzzer}}:

\begin{enumerate}
    \item Положить в корень дерева стартовую вершину и добавить её в очередь вершин.
    \item Взять текущую вершину из очереди.
    \item Если текущая вершина - терминальная, то перейти к следующей вершине.
    \item Каким-то способом выбрать продукцию из правила вывода для текущего нетерминала и добавить все символы из неё в очередь.
    \item Перейти к шагу два.
\end{enumerate}

Все известные методы опираются при выборе продукции нетерминала в пункте 4 на вероятности, то есть каждой продукции каждого нетерминала задаётся вероятность её выбора. Разные алгоритмы отличаются друг от друга способом задания этой вероятности. 

\begin{itemize}
\item Выбирать продукцию равновероятно для каждого нетерминала\cite{litlink6}. Плюсы - простая реализация. Минусы - часто будут генерироваться похожие тесты, медленно покрываюся всевозможные ветки деревьев. Например: если у стартового символа одна из продукций - один терминальный символ, то большая часть сгенерированных тестов будет состоять из этого символа.
\item Алгоритм построения похожих\cite{litlink1}. Если имеется какое-то множество примеров, то каждый из них представляется в виде AST и для каждого нетерминала для каждой продукции подсчитывется частота её встречаемости. По этим частотам можно вычисляется вероятность выбора каждой продукции. Чем чаще встречается переход в тестах, тем чаще он будет использоваться. Плюсы - этот метод позволяет направлять фаззер, путём изменения множества. Выбор символа становится более осмысленным с точки зрения программирования. Минусы - требуется начальное множество тестов.
\item Алгоритм построения отличных\cite{litlink1}. Отличие этого способа от предыдущего - вероятность выбора становится обратно пропорциональна частоте встречаемости, то есть чем чаще встречается переход в тестах, тем реже он будет генерироваться. Это позволяет двигаться фаззеру в противоположном направлении. Плюсы - чаще будут встречаться неожиданные пути в грамматике. Минусы - чаще будут попадаться неинтересные символы. Например, в javascript часто будет вызываться return. 
\item Ещё один способ - задать вероятности пропорционально количеству возможных поддеревьев в продукции\cite{litlink6}. Если в вершине потенциально много поддеревьев, она будет чаще выбираться.
Плюсы - позволяет наиболее полно покрыть грамматику. 
Минусы - требуется предпосчёт количества деревьев для каждого нетерминала.
\end{itemize}

\subsubsection{Свойства сгенерированных тестов}
\indent

Сгенерированные тесты должны не только быть синтаксически корректными, но и обладать полезными для fuzz-тестирования свойствами.

\begin{itemize}
\item Нужно стремиться создавать короткие тесты. Чем тест длиннее - тем дольше он будет выполняться в SUT, тем сложнее его анализировать, тем дольше будет его обработка\cite{litlink2}. 
\item Чем тест сложнее и рекурсивнее, тем вероятнее найти на нём ошибку SUT\cite{litlink2}. 
\end{itemize}

Эти свойства не противоречат друг другу. Рассмотрим примеры для грамматики с рисунка \ref{SimpleGrammar}. Выражение "5+5+5+5+5+5+5+5+5+5+5+5" является длинным, но не сложным. Скорее всего при парсинге будет вызвана функция обработки знака "+" несколько раз последовательно, что лишь увеличит время работы программы. Другой пример - выражение "(5 + (5) + ((5 + 5) + 5))". Оно короче предыдущего, но при обработке скобок некоторые функции будут вызваны рекурсивно, что увеличивает вероятность найти ошибку.

\subsection{Получение обратной связи от запуска теста на SUT}
\indent

Получение обратной связи от запуска теста - важная часть фаззера. Именно она часто позволяет определять значимость входного набора данных. Метрики, которые полезно оценивать:

\begin{itemize}
\item Самая весомая метрика - возникновение в SUT искомых исключений,
например double free\footnote[1]{\href{https://owasp.org/www-community/vulnerabilities/Doubly\_freeing\_memory}{https://owasp.org/www-community/vulnerabilities/Doubly\_freeing\_memory}} в языке программирования c++. Зачастую такие ошибки означают, что найден баг и этот тест нужно дополнительно исследовать вручную.
\item Покрытие кода(line coverage)\cite{litlink3} и покрытие функций(function coverage)\cite{litlink9} - подсчёт количества строк/функций, которые покрыл тест. В контесте множества тестов можно выявлять те, которые попадают в новые строки/функции. Разным строкам и функциям можно давать разный вес при подсчёте метрики. Это позволяет направлять фаззер в сторону исследования этих функций.
\item Покрытие веток(путей)\cite{litlink9} - более сложный вариант предыдущей метрики. При подсчёте учитывается последовательность выполнения строк кода или вызывов функций. Плюсы - покрытие веток гораздо более информативная метрика, чем предыдущая. Минусы - число веток растёт очень быстро с увеличением количества кода в SUT.
\end{itemize}

\subsection{Оценка полезности теста}
\indent

После запуска теста требуется узнать полезен ли этот тест или от него можно отказаться. Для этого нужно научиться сравнивать различные входные данные друг с другом.
Для этого введём функцию $value : \mathbb {X} \rightarrow \mathbb {R}$, которая каждому тесту ставит в соответствие его численную оценку. Конкретных реализаций этой функции может быть много. Приведём основные параметры, от которых она может зависеть(на основе статьи \cite{litlink2}):
\begin{itemize}
    \item При наличии исключения при запуске, значение функции становится бесконечным.
    \item Чем больше покрытие кода, тем больше значение функции. Если тест покрывает новый участок кода, то функцию можно сделать равной бесконечности.
    \item Чем короче тест, тем больше значение функции.
    \item Чем тест разнообразнее, то есть чем больше символов грамматики он покрывает, тем лучше.
\end{itemize}

\subsection{Способы обработки тестового множества}
\indent

Существует две стратегии обработки тестового множества:

\begin{enumerate}
\item Первая - наиболее часто встречающаяся - обрабатывать каждый тест по отдельности\cite{litlink9}. Это позволяет распараллелить процесс fuzz-тестирования, что серьёзно его ускоряет. 
\item Вторая стратегия основана на теории эволюции Дарвина\cite{litlink2}. Выбирается множество тестов. Для них всех рассчитывается функция полезности. Затем начинается процесс "выживания". Какой-то процент (например 10) тестов с наибольшей функцией полезности объявляется выжившими. Остальные случайным образом делятся на группы, в которых выживает несколько сильнейших. Потом среди оставшихся несколько случайных тестов объявляются выжившими. Тесты, которые не выжили отбрасываются.
\end{enumerate}

\subsection{Методы улучшения тестов}
\indent

Все успешные тесты необходимо преобразовывать для продолжения процесса fuzz-тестирования. Целями улучшения могут быть: 
\begin{itemize}
\item Поиск наиболее оптимального теста с точки зрения фаззера, обладающего теми же свойствами, что и улучшаемый. Другими словами - оптимизация процесса fuzz-тестирования.
\item Дальнейшее продвижение фаззера, в том числе выход из локальных экстремумов.
\end{itemize}

\subsubsection{Уменьшение размера теста}
\indent

Как было отмечено ранее, у коротких тестов есть ряд преимуществ по сравнению с длинными. Уменьшенный тест должен сохранить все полезные свойства длинного. Например, если старый тест покрывает какую-то новую функцию, то и новый должен покрывать эту функцию. Стандартные методы минмизации:

\begin{itemize}
\item Самый простой способ заключается в построении AST теста и поочерёдном удалении поддеревьев\cite{litlink6}. Если после удаления поддерева, полезность теста не уменьшилась, то старый тест заменяется на новый, и продолжается процесс минимизации. Плюсы - неплохая скокорость работы. С небольшой вероятностью тест  существенно укоротится. Минусы - удаление поддерева может сделать тест синтаксически некорректным. Этот способ охватывает только очень локальные изменения теста.
\item Уменьшение поддерева\cite{litlink3}. Способ похож на предыдущий, только вместо отбрасывания поддерева, оно заменяется на более короткое. Новый тест всегда будет синтаксически корректным, но перебор всех поддеревьев может занять длительное время.
\item Рекурсивное замещение поддерева\cite{litlink6}. По сути этот способ является эвристикой предыдущего. Если в вершине у нетерминала F есть сын F, то производится замена поддерева текущей вершины на поддерево сына. Такое изменение оставит тест синтаксически корректным и приведёт к его упрощению для фаззера. Минус - этот способ может быть редко применим.
\item Контролировать размер во время построение теста\cite{litlink5}. Этот способ применим, если используется генерация тестов. Тогда этап уменьшения можно опустить.
\end{itemize}

\subsubsection{Мутации}
\indent

Мутации являются двигателем фаззера, позволяют ему эволюционировать. Если фаззер "застрял" на каком-то этапе, то мутации могут сделать шаг в сторону и процесс fuzz-тестирования продолжится. Если тесты представимы в виде AST, то удобно описывать мутации изменениями над AST. 

\begin{itemize}
\item Скрещивание тестов друг с другом\cite{litlink4}. Берустя два успешных теста, представляются в виде AST, и поддерево одного теста заменяется на поддерево другого согласно правилам грамматики. Такое изменение, например, позволяет быстро увеличивать покрытие веток SUT.   
\item Создаётся пул поддеревьев\cite{litlink3}. Для каждой вершинки в AST теста считается  какая-то дополнительная информация. Поддерево этой вершинки может быть заменено только на поддерево из пула с такой же информацией. Например, информацией может быть тип нетерминала, количество идентификаторов. В пул тестов добавляются поддеревья из тестов, которые дают существенное улучшение полезности. Эта мутация позволяет обращать больше внимания на прогресс в фаззере. Например, если тестом покрыта какая-то новая функция, то среди новых тестов будет много тех, которые эту функцию исследуют. Сохранение дополнительной информации позволяет увеличить вероятность попадания в новую функцию.
\item Рекурсивное дублирование поддерева\cite{litlink6}. Это обратное действие одному из способов уменьшения. Эта мутация направлена на усложнение структуры выполняемого кода в SUT, например, на создание вложенных циклов или рекурсии. 
\item Применимы стандартные AFL\footnote[1]{\href{https://github.com/google/AFL}{https://github.com/google/AFL}} мутации - бит флип, замена "интересных значений". Они более случайны, их имеет смысл применять, когда остальные не работают. После применения этой мутации тест может стать синтаксически некорректным.
\item Замена поддерева на случайно сгенерированное\cite{litlink6}. Эта мутация - адаптированная для fuzz-тестирования с грамматикой версия предыдущего пункта. Основное отличие - тест останется корректным.
\item При использовании метода генерации тестов по вероятностной грамматике можно изменять вероятности генерации продукции для конкретного нетерминала\cite{litlink2}. Можно изменять на случайные, можно просто немного прибавить или отнять вероятности у нескольких символов. Новые тесты могут сильно отличаться от предыдущих. Плюс такой мутации - не нужно работать с самими тестами, достаточно просто изменить вероятность при генерации.  
\end{itemize}


\newpage
\section{Анализ инструментов предметной области}
\indent

Цель анализа - рассмотреть работу инструментов, которые применяются при fuzz-тестировании программ или решают задачу генерации входных данных. В обзоре рассмотрены самые цитируемые актуальные статьи с google scholar. 

Для этого требуется оценить каждый из инструментов по критериям, описанным в предыдущем пункте, и сделать вывод о возможности переиспользования этого инструмента при разработке фаззера. Критерии: 
\begin{enumerate}
    \item Получение начального пула тестов
    \item Способ генерации тестов
    \item Метрики, получаемые от запуска теста
    \item Оценка полезности теста
    \item Стратегия обработки тестов
    \item Мутации и способы улучшения тестов
\end{enumerate}

Для каждого из пунктов требуется ответить на вопросы: как инструмент решает задачу, какая конкретно реализация используется. 


\subsection{Superion}
\indent

Superion\cite{litlink3} - grey-box fuzzer, созданный на основе AFL. Является линией отсчёта для остальных рассматриваемых фаззеров. Разбор Superion по критериям: 
\begin{enumerate}
    \item Подразумевается, что начальный пул тестов уже имеется.
    \item Генерация тестов не используется.
    \item В Superion используется стандартное покрытие AFL - покрытие веток. В реализации происходит подсчёт всех веток, которые покрыл тест, и количество проходов по ним.
    \item Функция полезности - при увеличении покрытия, тест обозначается успешным.
    \item Каждый тест обрабатывается по отдельности.
    \item Улучшение тестов:
    \begin{itemize}
        \item Для уменьшения размера тестовых данных используется самая простая стратегия - удаление поддеревьев. В статье делается следующий вывод: "Таким образом, несмотря на относительно низкий коэффициент обрезки, эта стратегия обрезки с учетом грамматики может значительно улучшить коэффициент валидности для тестовых входных данных после обрезки, что облегчает и ускоряет дальнейшую работу с ними."
        \item Используется мутация скрещивания тестов. Реализация: берётся текущий тест и случайный из очереди длины не более 10000 байт. Они парсятся и из их поддеревеьев формируется множество для мутаций. Берётся не больше 10000 поддеревеьев и длина не более 200 байт.
        Затем каждое поддерево текущего теста заменяется на каждое поддерево из множества, формируя новый тест.\\
        Плюсы: очень подробный перебор возможных тестов.\\
        Минусы: несмотря на ограничения тестов получается очень много. Довольно большая проблема фаззера - время подготовки данных. Если программа выполняется t секунд, то время на мутации примерно t/3.
        \item Применяется мутация замены по словарю. В каждое корректное, согласно грамматике, место вставляется значение из множества стандартных для грамматики конструкций. Делается предположение, что все токены должны состоять из цифр и букв. Словарь токенов можно либо составить вручную, либо взять самые популярные токены из множества тестов. При мутации новый токен либо вставляется между двумя старыми, либо заменяет один из них.
    \end{itemize}
    В статье сравнивали различные мутации. Самыми удачными оказались мутация замены поддеревьев и перезапись токенов при помощи словаря, определённого человеком.
\end{enumerate}
Superion хорошо себя показал при сравнении с обычным AFL и jsfunfuzz - специальным фаззером для js. Тестирование проводилось на парсерах xml и интерпретаторах javascript.

\subsection{Grammarinator}
\indent

Grammarinator\cite{litlink5} - инструмент, позволяющий генерировать тестовые данные по имеющейся грамматике. Так как это неполноценный фаззер, имеет смысл описать только некоторые критерии.

\begin{enumerate}
\item При создании тестов используется равновероятная грамматика с небольшими улучшениями. После выбора какого-то правила вероятность его повторного выбора уменьшается. Такой подход помогает направлять
поколение к менее посещаемым частям грамматики. Во премя генерации контролируется размер тестов. Для каждого символа грамматики производится предподсчёт минимального размера поддерева и при генерации выбираются только те символы, поддеревья которых не превысят заданную длину теста. В Grammarinator используется алгоритм переиспользования токенов. Это позволяет уменьшить количество тестов с семантическими ошибками. Например, при fuzz-тестировании интерпертатора javascript будет сгенерировано меньше тестов с ошибкой "использование необъявленной переменной".
\item Создаётся пул тестов, которые используются для ускорения создания тестовых примеров с помощью эволюционных методов. Одна из возможностей заключается в выполнении случайной рекомбинации деревьев из пула для создания новых тестовых примеров. Другой вариант - деревья из пула используются, как поддеревья генерируемых тестов.
\end{enumerate}


\subsection{Nautilus}
\indent
Nautilus\cite{litlink6} - фаззер, сочетающий в себе способность генерировать входные данные по грамматике и ориентироваться на покрытие кода. Разбор Nautilus по критериям:

\begin{enumerate}
\item Начальный пул тестов не нужен.
\item Тестировались два варианта генерации: равновероятный по грамматике и равномерный по количеству возможных поддеревьев. В статье методы тестировали на разных интерпретаторах: для некоторых лучше работал второй метод, для некоторых одинаково.
\item Используемая метрика - покрытие строк кода.
\item Функция полезности - при увеличении покрытия, тест обозначается успешным.
\item Тесты обрабатываются по отдельности.
\item Улучшение тестов:
    \begin{itemize}
        \item Используется две стратегии уменьшения тестов. Минимизация поддерева - для каждого нетерминала изменяется поддерево на минимально возможное поддерево в этом нетерминале и проверяется покрытие. Далее применяется рекурсивная минимизация. Её цель состоит в том, чтобы уменьшить количество рекурсий, заменяя их по одной за раз. Из этих стратегий лучше работает первая.
        \item К каждому тесту применяется одна из следующих мутаций. 
        \begin{enumerate}    
        \item Случайное поддерево изменяется на случайно сгенерированное поддерево.
        \item Каждая вершина меняется на дерево, сгенерированное по смежным правилам.
        \item Рекурсивная мутация - если у нетерминала, есть сын, совпадающий с нетерминалом, повторяем его $ 2^n $ раз, $ n $ - небольшое.
        \item Скрещивание деревьев. Скрещивание происходит только между тестами, покрывающими новые участки кода.
        \item Мутации АФЛ.
        \end{enumerate}
        В начале процесса fuzz-тестирования лучше всего себя показывает первый тип мутаций. Через некоторое время скрещивание обгоняет его.
    \end{itemize}
\end{enumerate}

\subsection{EvoGFuzz}
\indent

В EvoGFuzz\cite{litlink2} идея строить тесты по грамматике с вероятностями является ключевой. Удалось спроектировать фаззер так, что почти весь код является реализацией генерации теста. Мутации опираются на вероятности в грамматике. 
\begin{enumerate}
    \item Требуется множество тестов для создания грамматики с вероятностями.
    \item Для генерации входных данных используется грамматика с вероятностями. При создании контролируется размер входных данных. 
    \item При запуске теста требуется получать только информацию об исключениях.
    \item Функция полезности выглядит следующим образом:\\
    $f(x) = \infty$ , если тест упал с ошибкой\\
    $f(x) = expansions(x) ^ 2 / length(x) $,\\
    $expansions(x)$ - количество расширений(нетерминальных символов) \\
    $length(x)$ - длина теста в символах.\\
    Использование такой функции позволяет более сложным тестам получать большую полезность, а длинные тесты штрафуются. 
    Плюсы: функция просто вычисляется, учитывает свойства, которые требуется получить от теста.
    Минусы: Тесты могут получаться длинными в терминах грамматики.
    \item Используется стратегия эволюции тестов. Запускается всё множество тестов и для каждого вычисляется функция полезности. Остаётся примерно 5\% тестов, с максимальной функцией качества. Среди не вошедших в топ 5\% случайным образом формируется 10 групп по 10 тестов, и победители остаются для дальнейшей работы.
    \item Единственная мутация - для каждого нового поколения выбирается случайный нетерминал в грамматике, и вероятности перехода из него меняются на случайные.
\end{enumerate}

\subsection{Выводы}
\indent

Для fuzz-тестирования шаблонизаторов предлагается использовать наиболее отличившиеся идеи. Среди будущих мутаций должны присутствовать изменение вероятностей на случайные, скрещивание и замена поддерева на случайное, потому что они выделяются среди остальных. Для генерации тестов можно использовать алгоритм построения похожих, вероятности вычислить по реальным программам. Для борьбы с семантическими ошибками можно использовать идеи из Grammarinator. Среди стратегий обработки тестов нет явно выделяющейся, но идеи, описанные в EvoGFuzz, мало изучены, предлагается исследовать именно их.


\newpage
\section{Описание работы реализованного фаззера}
\indent

Общую схему разработанного фаззера можно видеть на рисунке \ref{FuzzerArch}. Рассмотрим каждый из этапов подробнее.
\begin{figure}[ht!]
    \includegraphics[width=180mm]{FuzzerArch.png}
    \caption{Схема работы фаззера}
    \label{FuzzerArch}
    \end{figure}


\subsection{Получение грамматики шаблонизатора}

Для работы фаззера необходима грамматика, по которой он будет создавать тестовые данные. За основу взята грамматика, найденная на гитхабе\footnote{\href{https://gist.github.com/bluven/054e59be17d758ccce76bdf432c9d08c}{https://gist.github.com/bluven/054e59be17d758ccce76bdf432c9d08c}}. В процессе исследования в ней потребовались значительные преобразования для использования в фаззере. Во-первых, она была дополнена, чтобы соответствовать актульным возможностям шаблонизатора. Во-вторых, было заменено правило, которое генерировало произвольный текст между управляющими конструкциями шаблонизатора, на правило, которое создаёт различные контексты и места, в которых может встретиться уязвимость xss. Такие места были взяты из тестов инструмента DOMPurify\footnote{\href{https://github.com/cure53/DOMPurify/blob/main/test/test-suite.js}{https://github.com/cure53/DOMPurify/blob/main/test/test-suite.js}}.

Для выявленной на этапе анализа задачи проблемы соответствия названий переменных в шаблоне и в структуре данных предлагается следующее решение: для каждого стандартного типа данных зафиксировать название переменных, которые ему соответствуют. Но при этом добавить возможность иногда обращаться к несуществующим переменным для полноты покрытия(шаблонизатор должен корректно обрабатывать данную ситуацию и выдавать ошибку). Фиксирование названий не отразится на чистоте эксперимента, потому что по прежнему проверяется весь функционал шаблонизатора. Для реализации этой идеи в грамматике было изменено правило генерации названий переменных и  функций с произвольных строковых значений на фиксированные.

\subsection{Получение начального корпуса входных данных}

Как было отмечено в результатах анализа, фаззер создаёт более интересные входные данные, если вероятности в грамматике соответсвуют реальным вероятностям использования переходов грамматики. Для начльного множества тестов были собраны 34 шаблона из настоящих проектов с сайта github\footnote{\href{https://github.com/search?l=Go\&q=html\%2Ftemplate\&type=code}{https://github.com/search?l=Go\&q=html\%2Ftemplate\&type=code}}. Перед тем, как фаззер сможет обработать эти шаблоны, они проходят предварительную обработку: все символы между управляющими конструкциями заменяются на строку TEXT. Сами символы не имеют значения для фаззинга, важен только контекст, в котором будет выполняться логика шаблонизатора, а в $95\%$ случаев в данных от пользователей - это обычный HTML контекст.

\subsection{Создание грамматики с вероятностями}
Входные данные для этого этапа - обычная грамматика, множество шаблонов и (опционально) грамматика с вероятностями из прошлой эпохи фаззинга. На выходе должна получиться новая грамматика с вероятностями. Фаззер действует следующим образом:

\begin{enumerate}
    \item Нужно получить количество переходов для каждого из правил грамматики. Antlr4\footnote{\href{https://github.com/antlr/antlr4}{https://github.com/antlr/antlr4}} - инструмент, который генерирует парсер и лексер по грамматике. При этом у него есть возможность встроить в парсер произвольный код на языке программирования python. Каждый из шаблонов парсится при помощи скрипта, сгенерированного инструментом antlr4, при этом происходит подсчёт количества переходов в каждом из нетерминалов грамматики.
    \item Далее нужно преобразовать количество переходов в вероятности по формуле $probability (A => A_i) = \frac{cnt(A => A_i)}{\sum_{i=1}^{N}cnt(A => A_i)}$, где  $probability (A => A_i)$ - вероятность перехода из нетерминала $A$ в продукцию $A_i$, а $cnt(A => A_i)$ - количество таких переходов, полученное в пункте 1.
    \item (опциональный шаг) Следующий шаг разработан в рамках данной работы на основании запусков фаззера. Иногда бывает полезно учитывать грамматику из предыдущих эпох, чтобы не упираться в локальные максимумы. Поэтому было принято решение попробовать не просто заново пересчитывать вероятности, а добавить в формулу вероятности из прошлой эпохи с коэффициентом $\lambda$(коэффициент устаревания). Тогда формула примет следующий вид: $probability (A => A_i) = \lambda \cdot \frac{cnt(A => A_i)}{\sum_{i=1}^{N}cnt(A => A_i)} + (1 - \lambda) \cdot old\_probability (A => A_i)$. Данное преобразование не нарушает свойств вероятности.
    \item (Только для первой эпохи) Начальные вероятности для правил выбора названий переменных и функций, а также правил подстановки контекста выставлены вручную и примерно соответвуют равномерному распределению. Это связано с тем, что данные правила были добавлены в грамматику в рамках решения задачи, и нет данных, по которым можно было бы автоматически подсчитать их вероятности.
\end{enumerate}

\subsection{Мутации}

Мутации применяются только если не было изменений в покрытии в течение двух или более эпох. В фаззере реализовано два типа мутаций, какая из них будет применена - выбирается случайным образом.
\begin{itemize}
    \item Первая - изменение вероятностей в одной из строчек на случайные.
    \item Вторая - изменение всех вероятностей в грамматике на обратные, то есть генерация данных методом наименее похожих.
\end{itemize}

\subsection{Создание шаблонов новой эпохи}

Для генерации шаблонов по грамматике с вероятностями исползуется инструмент tribble\footnote{\href{https://github.com/havrikov/tribble}{https://github.com/havrikov/tribble}}. Количество тестов и глубина их AST - параметры, которые указываются в инструменте. Значения этих параметров перебирались для поиска оптимальных.

\subsection{Запуск тестов}

Для запуска тестов помимо шаблона нужно сгенерировать код на языке Golang, который будет обрабатывать этот шаблон. При этом требуется сгенерировать структуру, которая будет подана на вход шаблонизатору, как пользовательские данные. Большинство полей структуры заполняется строковыми константами - векторами xss атак, при помощи которых в будущем будет определяться отсутствие экранирования символов. Эти векторы взяты из тестов инструмента DOMPurify \footnote{\href{https://github.com/cure53/DOMPurify/blob/main/test/test-suite.js}{https://github.com/cure53/DOMPurify/blob/main/test/test-suite.js}}. 
Для решения проблемы бесконечного числа функций, которые можно использовать в шаблоне, предлагается определить только две и в шаблоне генерировать только их вызовы: первая возвращает одну из предварительно выбранных строковых констант, вторая просто возвращает свой первый аргумент. 

Дополнительно каждый тест запускается дважды - первый раз, как отдельный юнит-тест модуля html/template, второй раз - как отдельный юнит-тест модуля text/template. Таким образом, каждый шаблон запускается несколько раз с различными входными данными.



\subsection{Получение информации о покрытии}

Для получение информации о покрытии используется встроенные в язык программирования Golang методы\footnote{\href{https://go.dev/blog/cover}{https://go.dev/blog/cover}}. Тест запускается командой go test -covermode count. После прогона теста создастся файл с информацией о том, какие строчки исследуемого кода были выполнены при запуске, и сколько раз это произошло. Покрытие всех запусков одного шаблона объединяется в один файл. 

\subsection{Поиск ошибок экранирования}

В случае успешного выполнения теста, создастся html-документ, который нужно проверить на наличие неэкранированного вектора атаки xss. Для этого используется инструмент puppeteer\footnote{\href{https://pptr.dev/}{https://pptr.dev/}}. Puppeteer - это высокоуровневая библиотека Node.js, разработанная командой Chrome для автоматизации и контроля над веб-браузером. Он предоставляет простой и удобный API для работы с Chromium (или Google Chrome) через сетевой протокол DevTools.Puppeteer обладает широким набором функций для автоматизации веб-браузера, включая навигацию по страницам, заполнение и отправку форм, создание скриншотов и PDF-файлов, эмуляцию устройств и многое другое. Кроме того, Puppeteer поставляется с функциональностью для исполнения страниц, которая позволяет эмулировать действия пользователя на веб-странице, такие как нажатие кнопок, ввод текста, скроллинг и т.д., что обеспечивает более реалистичное взаимодействие с веб-сайтом. Именно эта возможность используется в фаззере. Все векторы атак исполняют одну и ту же javascipt функцию - alert. При помощи puppeteer, html-документ открывается в headless-браузере, при этом отслеживается событие всплывающего окна - по сути вызов функции alert. Если событие произошло - значит найдена потенциальная уязвимость. Шаблон откладывается, чтобы можно было верифицировать уязвимость вручную. 

\subsection{Отбор успешных шаблонов}

Этот шаг нужен для того, чтобы сформировать список шаблонов, которые будут влиять на дальнейшую работу фаззера. Нужно оценить каждый из шаблонов на основании результатов запуска. Функция полезности шаблона зависит от покрытия кода и наличия ошибки экранирования, и выглядит следующим образом:

\[
f(template) = 
\begin{cases}
    1 & \quad \text{если покрыты новые строчки кода или обнаружена уязвимость}\\
    0 & \quad \text{в противном случае}
\end{cases}
\]

В новое поколение шаблон попадает тогда и только тогда, когда его функция полезности равна 1.

\newpage
\section{Эксперименты}
\indent
Цель экспериментов - найти оптимальные параметры фаззера и сделать вывод о применимости методов fuzz-тестирования для тестирования шаблонизаторов.

\subsection{Методика проведения экспериментов}

У фаззера есть 3 основных параметра, для которых требуется найти оптимальные значения. Это максимальная глубина AST генерируемого шаблона, количество шаблонов в каждом поколении и коэффициент устаревания. Также требуется сравнить и оценить полезность применяемых мутаций. Оптимизируемая метрика - покрытие строк в процентах. Для поиска оптимальных параметров используется итеративный подход. Начальное приближение - глубина 10, количество шаблонов 10, коээфициент устаревания - 0.8. Далее осуществляется поиск оптимального значения для каждого из параметров по отдельности в следующем порядке: глубина, количество шаблонов в поколении, коэффициент. Для каждого возможного значения параметра фаззер работает 100 эпох, после чего фиксируется значение покрытия. Во время работы фаззера используются обе мутации. Среднее время одного прогона - 4 часа. 

\begin{figure}[ht!]
    \includegraphics[width=170mm]{depth.png}
    \caption{Зависимость покрытия от глубины AST}
    \label{Depth}
    \end{figure}

Оптимальное значение глубины генерируемых тестов - 10(рисунок \ref{Depth}). При такой глубине дерева, каждый шаблон содержит в себе несколько(2-3) контекстов и конструкций шаблонизатора. Если глубина меньше 10, генерируются недостаточно разнообразные шаблоны. Если больше 10, то возрастает вероятность ошибки обработки теста шаблонизатором.

\begin{figure}[ht!]
    \includegraphics[width=170mm]{generation.png}
    \caption{Зависимость покрытия от количества тестов в поколении}
    \label{Generation}
    \end{figure}

На графике(рисунок \ref{Generation}) видно, что метрика почти не изменяется, если тестов хотя бы 7. Самый выский показатель - 45.2\% достигнут при количетсве тестов - 21. Это объясняется тем, что в этом случае за 100 эпох было запущено в 3 раза больше тестов по сравнению со случаем, когда в поколении 7 тестов. Времени было также потрачено в 3 раза больше. Таким образом, можно сделать вывод, что оптимальное значение шаблонов в поколении - 7.

\begin{figure}[ht!]
    \includegraphics[width=160mm]{coef.png}
    \caption{Зависимость покрытия от коэффициента устаревания}
    \label{Coef}
    \end{figure}

Оптимальное значение коэффициента - 0.75 (рисунок \ref{Coef}). Действительно, при таком значении коэффициента, в сгенерированных тестах будет чаще срабатывать именно то правило грамматики, благодаря которому обнаружилось покрытие новых строк кода. В то же время остальные строчки частично сохранят вероятности прошлых эпох, что позволит и дальше генерировать разнообразные шаблоны.

\begin{figure}[ht!]
    \includegraphics[width=130mm]{mutations.png}
    \caption{Зависимость покрытия от используемых мутаций}
    \label{Mutations}
    \end{figure}

На гистограмме(рисунок \ref{Mutations}) демонстрируется сравнение эффективности разных мутаций. Наиболее полезна - мутация измененения вероятностей на случайные, так как она даёт наибольший прирост функции покрытия. Мутация изменения всех вероятностей в грамматике на обратные не даёт существенного улучшения. Наиболее оптимальный вариант - комбинировать эти мутации во время фаззинга, чаще используя первый тип.

Затем было проведено несколько запусков на лучших параметрах. Самый успешный из них набрал 45.6\% покрытия кода. Значение покрытия для каждой эпохи показано на рисунке \ref{BestRun}

\begin{figure}[ht!]
    \includegraphics[width=170mm]{BestRun.png}
    \caption{Лучший запуск}
    \label{BestRun}
    \end{figure}

\subsection{Найденные недостатки}

Недостаток в функции template.Execute(wr io.Writer, data any)\footnote{\href{https://pkg.go.dev/html/template\#Template.Execute}{https://pkg.go.dev/html/template\#Template.Execute}}. Если при выполнении шаблона или записи его выходных данных возникает ошибка, выполнение останавливается, но частичные результаты рендеринга шаблона будут записаны в буфер. Данный недостаток был автоматически обнаружен фаззером. Фаззер в процессе работы создаёт код на go, который использует эту функцию, записывая все шаблоны в один и тот же файл. Этот файл открывается для записи в начале программы. Важно отметить, что содержимое файла не очищается, а  переписывается новым шаблоном. Первым шагом фаззер записал в файл шаблон, в которым все символы были корректно экранированы. Затем в начало этого файла из-за ошибки при работе функции записалась только часть следующего шаблона. В результате в конце файла осталась последняя часть первого шаблона, что привело к срабатыванию функции alert, то есть возможной уязвимости. 

\subsection{Анализ результатов}

Покрытие кода оказалось на довольно низком уровне - 45.6\%. После анализа участков кода, которых фаззеру не удалось достичь, было выявлено, что в пакетах text/template и html/template присутствуют вспомогательные функции, которые не являются объектами исследования. После их удаления, процент покрытия стал равен 50.8\%.
Причины, по которым часть кода осталась непокрытой:
\begin{itemize}
    \item Недостаточно разнообразное множество контекстов, встроенных в грамматику. Шаблонизатор гранулярно обрабатывает все символы в тесте, поэтому для более полного покрытия нужно добавлять контексты, основываясь на исходном коде программы. Например, не был протестирован код экранирования символов в параметре ссылки(в html-атрибуте href)
    \item Использование в значениях переменных только векторов атаки xss. Из-за этого, например, остался не исследован код, работающий с числовыми константами, который теоретически может влиять на ход исполнения программы.
\end{itemize}

В ходе тестирования не удалось найти существенных недостатков в функциональности экранирования символов в шаблонизаторе. Это может быть связано как с высокой квалификацией разработчиков, так и с недостаточным покрытием исходного кода.

 
\subsection{Выводы}

В целом, идея использования грамматики с вероятностями для создания шаблонов себя полностью оправдала. Сгенерированные тесты получаются довольно сложными. С грамматикой очень удобно работать и строить вокруг неё весь процесс тестирования. В результате fuzz-тестирования был покрыт весь код, достижимый данной грамматикой. Слабым местом фаззера стала генерация кода, который вызывает функцию обработки шаблона. 

\begin{itemize}
    \item Использование мутаций над грамматикой с вероятностями позволяет выбираться из точек экстремумов.
    \item Выбор начальных вероятностей по реальным программам позволяет достигать довольно высокого покрытия на ранних эпохах тестирования
    .
    \item Использование обратной связи существенно ускоряет процесс фаззинга и позволяет автоматически направлять фаззер в сторону ещё не исследованного кода
    \item Разработанный метод с коэффициентом устаревания позволяет эффективно комбинировать вероятности прошлой и текущей эпохи. То есть новые вероятности учитывают разнообразие тестов старой эпохи, и новое покрытие текущей.
    \item Процесс fuzz-тестирования полностью автоматизирован
    \item Разработанный фаззер работает крайне медленно. При стандартных параметрах на 100 эпох тратится примерно 5 часов. Каждый сгенерированного шаблон требуется открыть инструментом puppeteer, что очень сильно замедляет работу и является узким местом всего фаззера.
\end{itemize}


Объекты дальнейшего исследования:

\begin{itemize}
    \item Улучшение грамматики, в частности добавление в неё новых контекстов.
    \item Использовать вместо метрики покрытия строк кода, метрику покрытия веток кода. Это позволит более точно управлять фаззером и анализировать его работу.
    \item Ускорить процесс проверки наличия ошибки экранирования.
    \item Добавление новых методов мутаций.
\end{itemize}

\newpage
\section{Результаты}
\indent

В рамках данной работы были получены следующие результаты:
\begin{itemize}
    \item Сделан обзор методов fuzz-тестирования программ, принимающих на вход данные, порождаемые КС-грамматикой. Выделены критерии для сравнения таких фаззеров.
    \item Произведён анализ существующих инструментов генерации входных данных. На его основе предложен алгоритм для fuzz-тестирования шаблонизаторов.
    \item Разработан полностью автоматический фаззер для стандартного шаблонизатора
    языка программирования Golang.
    \item Проанализирована работа фаззера.
    \item Сделаны выводы о применимости fuzz-тестирования для поиска ошибок в шаблонизаторе стандартной библиотеки языка Golang.
\end{itemize}

\newpage

\begin{thebibliography}{}
    \addcontentsline{toc}{section}{Список литературы}
    \bibitem{litlink1}  Inputs from Hell Generating Uncommon Inputs from Common Samples [Электронный ресурс]. URL: \href{https://arxiv.org/pdf/1812.07525.pdf}{https://arxiv.org/pdf/1812.07525.pdf} (дата обращения: 05.05.2023)
    \bibitem{litlink2}  Evolutionary Grammar-Based Fuzzing [Электронный ресурс]. URL: \href{https://arxiv.org/pdf/2008.01150.pdf}{https://arxiv.org/pdf/2008.01150.pdf} (дата обращения: 05.05.2023)
    \bibitem{litlink3}  Superion: Grammar-Aware Greybox Fuzzing [Электронный ресурс]. URL: \href{https://arxiv.org/pdf/1812.01197.pdf}{https://arxiv.org/pdf/1812.01197.pdf} (дата обращения: 05.05.2023)
    \bibitem{litlink4}  Fuzzing With Optimized Grammar-Aware
    Mutation Strategies [Электронный ресурс]. URL: \href{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9469897}{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9469897} (дата обращения: 05.05.2023)
    \bibitem{litlink5}  Grammarinator:
    A Grammar-Based Open Source Fuzzer [Электронный ресурс]. 
    URL: \href{https://www.researchgate.net/publication/328510752\_Grammarinator\_a\_grammar-based\_open\_source\_fuzzer}{Grammarinator}
    (дата обращения: 05.05.2023)
    \bibitem{litlink6}  NAUTILUS:
    Fishing for Deep Bugs with Grammars [Электронный ресурс]. URL: \href{https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019\_04A-3\_Aschermann\_paper.pdf}{Nautilus} (дата обращения: 05.05.2023)
    \bibitem{litlink7}  The Fuzzing Book [Электронный ресурс]. URL: \href{https://www.fuzzingbook.org/}{https://www.fuzzingbook.org/} (дата обращения: 05.05.2023)
    \bibitem{litlink8}  Systematically Covering Input Structure [Электронный ресурс]. URL: \href{https://publications.cispa.saarland/2971/1/ase19-paper381-published.pdf}{https://publications.cispa.saarland/2971/1/ase19-paper381-published.pdf} (дата обращения: 05.05.2023)
    \bibitem{litlink9}  American fuzzy lop - a security-oriented fuzzer [Электронный ресурс]. URL: \href{https://github.com/google/AFL}{https://github.com/google/AFL} (дата обращения: 05.05.2023)
    \bibitem{litlink10} Golang documentation [Электронный ресурс]. URL: \href{https://pkg.go.dev/}{https://pkg.go.dev/} (дата обращения: 05.05.2023)
    \bibitem{litlink11} Using type inference to make web templates robust against XSS [Электронный ресурс]. URL: \href{https://rawgit.com/mikesamuel/sanitized-jquery-templates/trunk/safetemplate.html\#problem\_definition}{https://rawgit.com/mikesamuel/sanitized-jquery-templates/trunk/safetemplate.html\#problem\_definition} (дата обращения: 05.05.2023)
    \bibitem{litlink12} The Definitive ANTLR 4 Reference [Электронный ресурс]. URL: \href{https://pragprog.com/titles/tpantlr2/the-definitive-antlr-4-reference/}{https://pragprog.com/titles/tpantlr2/the-definitive-antlr-4-reference/} (дата обращения: 05.05.2023)
\end{thebibliography}

\newpage

\appendix

\begin{landscape}
\section{Грамматика с вероятностями}

\begin{figure}[ht!]
    \includegraphics[width=260mm]{probabilities.png}
    \label{Probabilities}
    \end{figure}
\end{landscape}

\section{Пример сгенерированного шаблона}

\begin{figure}[ht!]
    \includegraphics[width=170mm]{Template.png}
    \label{GeneratedTemplate}
    \end{figure}

\end{document}
